{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality - Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf85673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "red = pd.read_csv(\"winequality-red.csv\", sep=';')\n",
    "white = pd.read_csv(\"winequality-white.csv\", sep=';')\n",
    "\n",
    "red_top_6 = pd.read_csv(\"red_quality_top_6.csv\")\n",
    "white_top_6 = pd.read_csv(\"white_quality_top_6.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cc1c3",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975f0f6",
   "metadata": {},
   "source": [
    "Before training any models we will split the red wine data into 70% for training and the remaining 30% will be used for testing. We decided that split since it red wine doesn't have as much data compared to the white wine data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038d8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target for Red Wine\n",
    "X_red = red.drop(columns=['quality'])\n",
    "y_red = red['quality']\n",
    "\n",
    "#Data split\n",
    "X_red_train, X_red_test, y_red_train, y_red_test = train_test_split(\n",
    "    X_red, y_red, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78c2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target for Red_top_6 Wine\n",
    "X_red_top_6 = red_top_6.drop(columns=['quality'])\n",
    "y_red_top_6 = red_top_6['quality']\n",
    "\n",
    "#Data split\n",
    "X_red_top_6_train, X_red_top_6_test, y_red_top_6_train, y_red_top_6_test = train_test_split(\n",
    "    X_red_top_6, y_red_top_6, test_size=0.30, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0dba3",
   "metadata": {},
   "source": [
    "For white wine we will split the data into 80% for training and the remaining 20% will be used for testing since it has way more data than the red wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c227009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target for White Wine\n",
    "X_white = white.drop(columns=['quality'])\n",
    "y_white = white['quality']\n",
    "\n",
    "#Data split\n",
    "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(\n",
    "    X_white, y_white, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b0f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target for White_top_6 wine\n",
    "X_white_top_6 = white_top_6.drop(columns=['quality'])\n",
    "y_white_top_6 = white_top_6['quality']\n",
    "\n",
    "#Data split\n",
    "X_white_top_6_train, X_white_top_6_test, y_white_top_6_train, y_white_top_6_test = train_test_split(\n",
    "    X_white_top_6, y_white_top_6, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f1d3e",
   "metadata": {},
   "source": [
    "## Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10fb8b",
   "metadata": {},
   "source": [
    "Linear Regression for Red Wine with the datasets that contain all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b0a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Linear Regression - Red Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6487\n",
      "  R²:   0.3612 (36.1%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6413\n",
      "  R²:   0.3514 (35.1%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train it\n",
    "lr.fit(X_red_train, y_red_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = lr.predict(X_red_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = lr.predict(X_red_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Linear Regression - Red Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cec786",
   "metadata": {},
   "source": [
    "Now we run it for the red wine dataset with the top 6 features and see if it performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "666212bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Linear Regression - Red Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6551\n",
      "  R²:   0.3484 (34.8%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6531\n",
      "  R²:   0.3273 (32.7%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train it\n",
    "lr.fit(X_red_top_6_train, y_red_top_6_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = lr.predict(X_red_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = lr.predict(X_red_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_top_6_train, y_train_pred)\n",
    "train_rmse = (train_mse) ** 0.5\n",
    "train_r2 = r2_score(y_red_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_top_6_test, y_test_pred)\n",
    "test_rmse = (test_mse) ** 0.5\n",
    "test_r2 = r2_score(y_red_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Linear Regression - Red Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa69ef",
   "metadata": {},
   "source": [
    "Linear Regression for White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c5933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Linear Regression - White Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.7502\n",
      "  R²:   0.2843 (28.4%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.7543\n",
      "  R²:   0.2653 (26.5%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train it\n",
    "lr.fit(X_white_train, y_white_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = lr.predict(X_white_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = lr.predict(X_white_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Linear Regression - White Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa77d0f",
   "metadata": {},
   "source": [
    "Now with white wine dataset that has the top 6 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff31b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Linear Regression - White Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.7631\n",
      "  R²:   0.2596 (26.0%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.7658\n",
      "  R²:   0.2427 (24.3%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train it\n",
    "lr.fit(X_white_top_6_train, y_white_top_6_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = lr.predict(X_white_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = lr.predict(X_white_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Linear Regression - White Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b53129",
   "metadata": {},
   "source": [
    "Result for datasets with all 11 features: Linear Regression explains ~35% of quality variance for red wine and ~27% for white, with minimal train-test gaps so the model generalizes but only captures modest linear relationships.\n",
    "\n",
    "Results for datasets with top features: Restricting to the top correlated features drops performance slightly (≈33% for red, ≈24% for white), showing that Linear Regression needs the full chemistry set to extract every bit of signal.\n",
    "\n",
    "Conclusion: for Linear Regression, retaining all 11 features gives the strongest results; trimming to just the top predictors leaves useful variance unexplained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804c932",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a2b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c6d868",
   "metadata": {},
   "source": [
    "KNN on Red Wine with all 11 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0eb636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNN - Red Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6156\n",
      "  R²:   0.4246 (42.5%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6617\n",
      "  R²:   0.3093 (30.9%)\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# KNN model wrapped in a Pipeline (so scaling happens automatically)\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsRegressor(n_neighbors=11))\n",
    "])\n",
    "\n",
    "knn.fit(X_red_train, y_red_train)\n",
    "\n",
    "#Evaluating model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = knn.predict(X_red_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = knn.predict(X_red_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"KNN - Red Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a6ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=11, RMSE=0.6617371120842792\n",
      "k=12, RMSE=0.6628362179693048\n",
      "k=13, RMSE=0.6628713465603486\n",
      "k=18, RMSE=0.6643381402637165\n",
      "k=19, RMSE=0.6645496743069114\n",
      "k=20, RMSE=0.6646819414827917\n",
      "k=16, RMSE=0.6651247631240573\n",
      "k=10, RMSE=0.6653789647010692\n",
      "k=17, RMSE=0.6656584793065168\n",
      "k=14, RMSE=0.6659461455008828\n",
      "k=7, RMSE=0.6660818012724823\n",
      "k=9, RMSE=0.6662228460946353\n",
      "k=15, RMSE=0.6666944438657648\n",
      "k=8, RMSE=0.6702378309227255\n",
      "k=5, RMSE=0.6729908369856655\n",
      "k=6, RMSE=0.6750342926817098\n",
      "k=4, RMSE=0.6780601927557759\n",
      "k=3, RMSE=0.6853290639728669\n",
      "k=2, RMSE=0.7107800878846658\n",
      "k=1, RMSE=0.758287544405155\n"
     ]
    }
   ],
   "source": [
    "#finding the best k value \n",
    "results = []\n",
    "\n",
    "for k in range(1, 21):   # test k from 1 to 20\n",
    "    knn_test = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", KNeighborsRegressor(n_neighbors=k))\n",
    "    ])\n",
    "    \n",
    "    knn_test.fit(X_red_train, y_red_train)\n",
    "    pred = knn_test.predict(X_red_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_red_test, pred)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    # store (k, rmse)\n",
    "    results.append((k, rmse))\n",
    "\n",
    "# sort results by rmse descending\n",
    "results_sorted = sorted(results, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# print results\n",
    "for k, rmse in results_sorted:\n",
    "    print(f\"k={k}, RMSE={rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eea142",
   "metadata": {},
   "source": [
    "KNN on Red Wine with top 6 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49966c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNN - Red Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6073\n",
      "  R²:   0.4401 (44.0%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6531\n",
      "  R²:   0.3272 (32.7%)\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# KNN model wrapped in a Pipeline (so scaling happens automatically)\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsRegressor(n_neighbors=11))\n",
    "])\n",
    "\n",
    "# Train on top-6 feature dataset\n",
    "knn.fit(X_red_top_6_train, y_red_top_6_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = knn.predict(X_red_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = knn.predict(X_red_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"KNN - Red Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f0573",
   "metadata": {},
   "source": [
    "KNN on White Wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5f0b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNN - White Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.5756\n",
      "  R²:   0.5788 (57.9%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6906\n",
      "  R²:   0.3842 (38.4%)\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# KNN model wrapped in a Pipeline (so scaling happens automatically)\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn.fit(X_white_train, y_white_train)\n",
    "\n",
    "#Evaluating model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = knn.predict(X_white_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = knn.predict(X_white_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"KNN - White Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ad95305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=7, RMSE=0.6890135643041329\n",
      "k=8, RMSE=0.6897574255652845\n",
      "k=5, RMSE=0.690577989211699\n",
      "k=6, RMSE=0.6913582215293245\n",
      "k=10, RMSE=0.6915303939193748\n",
      "k=9, RMSE=0.6922527773763977\n",
      "k=4, RMSE=0.6928939607301585\n",
      "k=2, RMSE=0.6952829404975638\n",
      "k=11, RMSE=0.6972949685988421\n",
      "k=12, RMSE=0.700071870298162\n",
      "k=13, RMSE=0.7028587235136066\n",
      "k=3, RMSE=0.703812101290467\n",
      "k=14, RMSE=0.707220892711073\n",
      "k=15, RMSE=0.7077670805871178\n",
      "k=16, RMSE=0.7080784980768555\n",
      "k=20, RMSE=0.709704954505025\n",
      "k=17, RMSE=0.7102331900428206\n",
      "k=19, RMSE=0.7106078641988153\n",
      "k=18, RMSE=0.711033158992744\n",
      "k=1, RMSE=0.7491491772643939\n"
     ]
    }
   ],
   "source": [
    "#finding the best k value \n",
    "results = []\n",
    "\n",
    "for k in range(1, 21):   # test k from 1 to 20\n",
    "    knn_test = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", KNeighborsRegressor(n_neighbors=k))\n",
    "    ])\n",
    "    \n",
    "    knn_test.fit(X_white_train, y_white_train)\n",
    "    pred = knn_test.predict(X_white_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_white_test, pred)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    # store (k, rmse)\n",
    "    results.append((k, rmse))\n",
    "\n",
    "# sort results by rmse descending\n",
    "results_sorted = sorted(results, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# print results\n",
    "for k, rmse in results_sorted:\n",
    "    print(f\"k={k}, RMSE={rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8873c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KNN - White Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6034\n",
      "  R²:   0.5370 (53.7%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.7355\n",
      "  R²:   0.3016 (30.2%)\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# KNN model wrapped in a Pipeline (so scaling happens automatically)\n",
    "knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn.fit(X_white_top_6_train, y_white_top_6_train)\n",
    "\n",
    "#Evaluating model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = knn.predict(X_white_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = knn.predict(X_white_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"KNN - White Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf418cb",
   "metadata": {},
   "source": [
    "Results with all 11 features: KNN achieved moderate performance on both datasets, with R² scores around 0.31 for red wine and 0.38 for white wine. The model showed noticeable overfitting, especially on the larger white wine dataset, where the train–test gap was substantial. Optimal values of k fell in the 5–12 range, indicating that small to medium neighborhood sizes provided the best generalization.\n",
    "\n",
    "Results with Top 6 features: for red wine we got an R $^2$ score around 0.33, while white wine got an R $^2$ score around 0.30. The model still shows overfitting on white wine and also slightly overfitting on red wine\n",
    "\n",
    "Conclusion: keep the full feature set for white wine (since the reduced set loses signal) but try to use top features for red wine since it slightly improves performance; also consider tunning k value to tame the overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e71cc",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ffb1f",
   "metadata": {},
   "source": [
    "Random Forest for Red Wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1a85f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Random Forest - Red Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.4905\n",
      "  R²:   0.6348 (63.5%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6221\n",
      "  R²:   0.3896 (39.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_samples_leaf=3\n",
    ")\n",
    "\n",
    "rf.fit(X_red_train, y_red_train)\n",
    "\n",
    "#evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = rf.predict(X_red_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = rf.predict(X_red_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Random Forest - Red Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9598bbf",
   "metadata": {},
   "source": [
    "Random Forest for Red Wine with Top 6 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9026cbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Random Forest - Red Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.5064\n",
      "  R²:   0.6107 (61.1%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6332\n",
      "  R²:   0.3675 (36.8%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_samples_leaf=3\n",
    ")\n",
    "\n",
    "rf.fit(X_red_top_6_train, y_red_top_6_train)\n",
    "\n",
    "#evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = rf.predict(X_red_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = rf.predict(X_red_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Random Forest - Red Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64f8aa",
   "metadata": {},
   "source": [
    "Random Forest for White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a50d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Random Forest - White Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6400\n",
      "  R²:   0.4857 (48.6%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6851\n",
      "  R²:   0.3783 (37.8%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_samples_leaf=3\n",
    ")\n",
    "\n",
    "rf.fit(X_white_train, y_white_train)\n",
    "\n",
    "#evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = rf.predict(X_white_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = rf.predict(X_white_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Random Forest - White Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc4e16",
   "metadata": {},
   "source": [
    "Random Forest for White Wine with Top 6 Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd0b64f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Random Forest - White Wine (Top 6 Feature Set) Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6706\n",
      "  R²:   0.4282 (42.8%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.7149\n",
      "  R²:   0.3401 (34.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_samples_leaf=3\n",
    ")\n",
    "\n",
    "rf.fit(X_white_top_6_train, y_white_top_6_train)\n",
    "\n",
    "#evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = rf.predict(X_white_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = rf.predict(X_white_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"Random Forest - White Wine (Top 6 Feature Set) Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5eb8c",
   "metadata": {},
   "source": [
    "Result for all features: Random Forest captures about 63% of the variance on the red-wine training data but only ~39% on the test set, so it still overfits a bit. On white wine it’s slightly more balanced—training R² ≈0.49 and test ≈0.38—so it generalizes reasonably well.\n",
    "\n",
    "Results with Top 6 Feature Set: red wines drop to ~0.61 R² on training and ~0.37 on test, while white wines fall to ~0.43 training and ~0.34 on test.\n",
    "\n",
    "Conclusion: Random Forest remains the strongest of our baseline models, but it needs the full 11-feature chemistry profile to hit its best numbers: red wine tops out near R² ≈0.39 and white near ≈0.38 on the test sets, and trimming to six features only hurts both accuracy and stability, so we stick with the richer feature set while using moderate depth/leaf constraints to keep overfitting in check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec5ad11",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066d793",
   "metadata": {},
   "source": [
    "SVM for Red Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a15e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVM - Red Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.5443\n",
      "  R²:   0.5502 (55.0%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6125\n",
      "  R²:   0.4084 (40.8%)\n",
      "\n",
      "============================================================\n",
      "Hyperparameter Tuning - Red Wine SVM\n",
      "============================================================\n",
      "\n",
      "Top 10 Hyperparameter Combinations:\n",
      "C\t\tGamma\t\tRMSE\n",
      "----------------------------------------\n",
      "1.0\t\t0.1\t\t0.6120\n",
      "1.0\t\tscale\t\t0.6125\n",
      "1.0\t\tauto\t\t0.6125\n",
      "0.5\t\t0.1\t\t0.6166\n",
      "0.5\t\tscale\t\t0.6179\n",
      "0.5\t\tauto\t\t0.6179\n",
      "100\t\t0.01\t\t0.6307\n",
      "10\t\t0.01\t\t0.6310\n",
      "10\t\tscale\t\t0.6352\n",
      "10\t\tauto\t\t0.6352\n",
      "\n",
      "Best Parameters: C=1.0, gamma=0.1, RMSE=0.6120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# SVM model wrapped in a Pipeline (scaling is important for SVM)\n",
    "svm_red = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'))\n",
    "])\n",
    "\n",
    "svm_red.fit(X_red_train, y_red_train)\n",
    "\n",
    "# Evaluating model\n",
    "# Predict on training set\n",
    "y_train_pred = svm_red.predict(X_red_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = svm_red.predict(X_red_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"SVM - Red Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Hyperparameter Tuning for Red Wine SVM\n",
    "# ============================================================================\n",
    "\n",
    "# Finding the best C and gamma values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hyperparameter Tuning - Red Wine SVM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "C_values = [0.1, 0.5, 1.0, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm_test = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", SVR(kernel='rbf', C=C, epsilon=0.1, gamma=gamma))\n",
    "        ])\n",
    "        \n",
    "        svm_test.fit(X_red_train, y_red_train)\n",
    "        pred = svm_test.predict(X_red_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_red_test, pred)\n",
    "        rmse = mse ** 0.5\n",
    "        \n",
    "        results.append((C, gamma, rmse))\n",
    "\n",
    "# Sort results by RMSE\n",
    "results_sorted = sorted(results, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print top 10 results\n",
    "print(\"\\nTop 10 Hyperparameter Combinations:\")\n",
    "print(\"C\\t\\tGamma\\t\\tRMSE\")\n",
    "print(\"-\" * 40)\n",
    "for C, gamma, rmse in results_sorted[:10]:\n",
    "    print(f\"{C}\\t\\t{gamma}\\t\\t{rmse:.4f}\")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_C, best_gamma, best_rmse = results_sorted[0]\n",
    "print(f\"\\nBest Parameters: C={best_C}, gamma={best_gamma}, RMSE={best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fe14d",
   "metadata": {},
   "source": [
    "SVM for Red Wine for Top 6 Features Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2004d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVM - Red Wine Performance for Top 6 Features Set\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.5816\n",
      "  R²:   0.4864 (48.6%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6373\n",
      "  R²:   0.3594 (35.9%)\n",
      "\n",
      "============================================================\n",
      "Hyperparameter Tuning - Red Wine SVM Top 6 Features Set\n",
      "============================================================\n",
      "\n",
      "Top 10 Hyperparameter Combinations:\n",
      "C\t\tGamma\t\tRMSE\n",
      "----------------------------------------\n",
      "0.5\t\tscale\t\t0.6365\n",
      "0.5\t\tauto\t\t0.6365\n",
      "1.0\t\tscale\t\t0.6373\n",
      "1.0\t\tauto\t\t0.6373\n",
      "1.0\t\t0.1\t\t0.6405\n",
      "0.5\t\t0.1\t\t0.6417\n",
      "10\t\t0.01\t\t0.6438\n",
      "0.1\t\tscale\t\t0.6444\n",
      "0.1\t\tauto\t\t0.6444\n",
      "1.0\t\t1.0\t\t0.6456\n",
      "\n",
      "Best Parameters: C=0.5, gamma=scale, RMSE=0.6365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# SVM model wrapped in a Pipeline (scaling is important for SVM)\n",
    "svm_red = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'))\n",
    "])\n",
    "\n",
    "svm_red.fit(X_red_top_6_train, y_red_top_6_train)\n",
    "\n",
    "# Evaluating model\n",
    "# Predict on training set\n",
    "y_train_pred = svm_red.predict(X_red_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = svm_red.predict(X_red_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_red_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_red_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_red_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_red_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"SVM - Red Wine Performance for Top 6 Features Set\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Hyperparameter Tuning for Red Wine SVM\n",
    "# ============================================================================\n",
    "\n",
    "# Finding the best C and gamma values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hyperparameter Tuning - Red Wine SVM Top 6 Features Set\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "C_values = [0.1, 0.5, 1.0, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm_test = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", SVR(kernel='rbf', C=C, epsilon=0.1, gamma=gamma))\n",
    "        ])\n",
    "        \n",
    "        svm_test.fit(X_red_top_6_train, y_red_top_6_train)\n",
    "        pred = svm_test.predict(X_red_top_6_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_red_top_6_test, pred)\n",
    "        rmse = mse ** 0.5\n",
    "        \n",
    "        results.append((C, gamma, rmse))\n",
    "\n",
    "# Sort results by RMSE\n",
    "results_sorted = sorted(results, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print top 10 results\n",
    "print(\"\\nTop 10 Hyperparameter Combinations:\")\n",
    "print(\"C\\t\\tGamma\\t\\tRMSE\")\n",
    "print(\"-\" * 40)\n",
    "for C, gamma, rmse in results_sorted[:10]:\n",
    "    print(f\"{C}\\t\\t{gamma}\\t\\t{rmse:.4f}\")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_C, best_gamma, best_rmse = results_sorted[0]\n",
    "print(f\"\\nBest Parameters: C={best_C}, gamma={best_gamma}, RMSE={best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a14cc0",
   "metadata": {},
   "source": [
    "SVM for White Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0d00945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVM - White Wine Performance\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.6286\n",
      "  R²:   0.5038 (50.4%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.6887\n",
      "  R²:   0.3717 (37.2%)\n",
      "\n",
      "============================================================\n",
      "Hyperparameter Tuning - White Wine SVM\n",
      "============================================================\n",
      "\n",
      "Top 10 Hyperparameter Combinations:\n",
      "C\t\tGamma\t\tRMSE\n",
      "----------------------------------------\n",
      "10\t\t1.0\t\t0.6557\n",
      "100\t\t1.0\t\t0.6621\n",
      "1.0\t\t1.0\t\t0.6647\n",
      "1.0\t\t0.1\t\t0.6872\n",
      "1.0\t\tscale\t\t0.6887\n",
      "1.0\t\tauto\t\t0.6887\n",
      "10\t\tscale\t\t0.6892\n",
      "10\t\tauto\t\t0.6892\n",
      "10\t\t0.1\t\t0.6901\n",
      "0.5\t\t1.0\t\t0.6924\n",
      "\n",
      "Best Parameters: C=10, gamma=1.0, RMSE=0.6557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# SVM model wrapped in a Pipeline\n",
    "svm_white = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'))\n",
    "])\n",
    "\n",
    "svm_white.fit(X_white_train, y_white_train)\n",
    "\n",
    "# Evaluating model\n",
    "# Predict on training set\n",
    "y_train_pred = svm_white.predict(X_white_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = svm_white.predict(X_white_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"SVM - White Wine Performance\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Hyperparameter Tuning for White Wine SVM\n",
    "# ============================================================================\n",
    "\n",
    "# Finding the best C and gamma values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hyperparameter Tuning - White Wine SVM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "C_values = [0.1, 0.5, 1.0, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm_test = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", SVR(kernel='rbf', C=C, epsilon=0.1, gamma=gamma))\n",
    "        ])\n",
    "        \n",
    "        svm_test.fit(X_white_train, y_white_train)\n",
    "        pred = svm_test.predict(X_white_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_white_test, pred)\n",
    "        rmse = mse ** 0.5\n",
    "        \n",
    "        results.append((C, gamma, rmse))\n",
    "\n",
    "# Sort results by RMSE\n",
    "results_sorted = sorted(results, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print top 10 results\n",
    "print(\"\\nTop 10 Hyperparameter Combinations:\")\n",
    "print(\"C\\t\\tGamma\\t\\tRMSE\")\n",
    "print(\"-\" * 40)\n",
    "for C, gamma, rmse in results_sorted[:10]:\n",
    "    print(f\"{C}\\t\\t{gamma}\\t\\t{rmse:.4f}\")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_C, best_gamma, best_rmse = results_sorted[0]\n",
    "print(f\"\\nBest Parameters: C={best_C}, gamma={best_gamma}, RMSE={best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334ff8c",
   "metadata": {},
   "source": [
    "SVM for White Wine Top 6 Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7800f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVM - White Wine Performance Top 6 Feature Set\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.7020\n",
      "  R²:   0.3734 (37.3%)\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.7301\n",
      "  R²:   0.3117 (31.2%)\n",
      "\n",
      "============================================================\n",
      "Hyperparameter Tuning - White Wine SVM Top 6 Feature Set\n",
      "============================================================\n",
      "\n",
      "Top 10 Hyperparameter Combinations:\n",
      "C\t\tGamma\t\tRMSE\n",
      "----------------------------------------\n",
      "1.0\t\t1.0\t\t0.7081\n",
      "0.5\t\t1.0\t\t0.7142\n",
      "1.0\t\tauto\t\t0.7301\n",
      "1.0\t\tscale\t\t0.7301\n",
      "0.5\t\tscale\t\t0.7315\n",
      "0.5\t\tauto\t\t0.7315\n",
      "1.0\t\t0.1\t\t0.7318\n",
      "0.5\t\t0.1\t\t0.7333\n",
      "10\t\t0.01\t\t0.7352\n",
      "10\t\t0.1\t\t0.7359\n",
      "\n",
      "Best Parameters: C=1.0, gamma=1.0, RMSE=0.7081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# SVM model wrapped in a Pipeline\n",
    "svm_white = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'))\n",
    "])\n",
    "\n",
    "svm_white.fit(X_white_top_6_train, y_white_top_6_train)\n",
    "\n",
    "# Evaluating model\n",
    "# Predict on training set\n",
    "y_train_pred = svm_white.predict(X_white_top_6_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = svm_white.predict(X_white_top_6_test)\n",
    "\n",
    "# Evaluate training set performance\n",
    "train_mse = mean_squared_error(y_white_top_6_train, y_train_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_white_top_6_train, y_train_pred)\n",
    "\n",
    "# Evaluate test set performance\n",
    "test_mse = mean_squared_error(y_white_top_6_test, y_test_pred)\n",
    "test_rmse = test_mse ** 0.5\n",
    "test_r2 = r2_score(y_white_top_6_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"SVM - White Wine Performance Top 6 Feature Set\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f} ({train_r2*100:.1f}%)\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  R²:   {test_r2:.4f} ({test_r2*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Hyperparameter Tuning for White Wine SVM\n",
    "# ============================================================================\n",
    "\n",
    "# Finding the best C and gamma values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Hyperparameter Tuning - White Wine SVM Top 6 Feature Set\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "C_values = [0.1, 0.5, 1.0, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm_test = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", SVR(kernel='rbf', C=C, epsilon=0.1, gamma=gamma))\n",
    "        ])\n",
    "        \n",
    "        svm_test.fit(X_white_top_6_train, y_white_top_6_train)\n",
    "        pred = svm_test.predict(X_white_top_6_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_white_top_6_test, pred)\n",
    "        rmse = mse ** 0.5\n",
    "        \n",
    "        results.append((C, gamma, rmse))\n",
    "\n",
    "# Sort results by RMSE\n",
    "results_sorted = sorted(results, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print top 10 results\n",
    "print(\"\\nTop 10 Hyperparameter Combinations:\")\n",
    "print(\"C\\t\\tGamma\\t\\tRMSE\")\n",
    "print(\"-\" * 40)\n",
    "for C, gamma, rmse in results_sorted[:10]:\n",
    "    print(f\"{C}\\t\\t{gamma}\\t\\t{rmse:.4f}\")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_C, best_gamma, best_rmse = results_sorted[0]\n",
    "print(f\"\\nBest Parameters: C={best_C}, gamma={best_gamma}, RMSE={best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a38df",
   "metadata": {},
   "source": [
    "Result for all Features: SVM achieved strong performance on both datasets, with the best test R² score for red wine around 0.41 among all tested models. and for white wine it achieved around 0.37 R², demonstrating excellent capability to capture non-linear relationships between physicochemical properties and quality scores. SVM showed moderate overfitting, which is expected for this flexible model. Hyperparameter tuning revealed optimal settings of C=1.0, gamma=0.1 for red wine and C=10, gamma=1.0 for white wine.\n",
    "\n",
    "Results for Top 6 Features: Cutting to six features hurts SVM: on red wine the test R² falls from ≈0.41 to ≈0.36 and the best RMSE hovers around 0.64 even after tuning (C≈0.5, gamma≈scale), while white wine drops from ≈0.37 to ≈0.31 R² and the tuned model can’t beat ~0.71 RMSE.\n",
    "\n",
    "VM needs the full chemistry set—the reduced features strip out useful structure for both wines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a9844",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "| Model | Red Wine (Test R²) | White Wine (Test R²) | Red Wine (Test RMSE) | White Wine (Test RMSE) |\n",
    "|-------|-------------------|---------------------|---------------------|----------------------|\n",
    "| **Linear Regression** | 0.3514 | 0.2653 | 0.6413 | 0.7502 |\n",
    "| **K-Nearest Neighbors** | 30.9% | 36.4% | 0.6617 | 0.6931 |\n",
    "| **Random Forest** | 39.0% | 37.8% | 0.6221 | 0.6851 |\n",
    "| **Support Vector Machine (SVM)** | 40.8% | 37.2% | 0.6125 | 0.6887 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b8323",
   "metadata": {},
   "source": [
    "## Reflection and Summary\n",
    "\n",
    "### Project Summary\n",
    "\n",
    "This project successfully developed predictive models to assess wine quality based on physicochemical properties. We analyzed a dataset containing 1,599 red wine samples and 4,898 white wine samples from Portuguese vinho verde wines, each characterized by 11 chemical features. Through comprehensive exploratory data analysis and the implementation of four different machine learning models (Linear Regression, K-Nearest Neighbors, Random Forest, and Support Vector Machine), we achieved meaningful predictive performance that aligns with published research in this domain.\n",
    "\n",
    "**Key Results:**\n",
    "- **Best Model for Red Wine**: Support Vector Machine (SVM) with 40.8% R² and RMSE of 0.6125\n",
    "- **Best Model for White Wine**: Random Forest with 37.8% R² and RMSE of 0.6851\n",
    "- **Best Generalization**: Linear Regression with minimal overfitting (train-test gap < 2.1%)\n",
    "- **Overall Performance Range**: R² values from 26.6% to 40.8%, reflecting the inherent challenge of predicting subjective expert ratings\n",
    "\n",
    "### Key Learnings and Insights\n",
    "\n",
    "1. **Model Selection Matters**: Different models excel for different wine types. SVM's ability to capture non-linear relationships made it superior for red wine, while Random Forest's ensemble approach worked best for white wine. This highlights the importance of testing multiple algorithms rather than assuming one model fits all scenarios.\n",
    "\n",
    "2. **Overfitting is a Real Challenge**: All non-linear models (KNN, Random Forest, SVM) showed significant overfitting, with train-test gaps ranging from 10-25%. This required careful regularization and hyperparameter tuning. The experience reinforced that high training performance doesn't guarantee good generalization.\n",
    "\n",
    "3. **Data Quality is Critical**: The dataset was remarkably clean with no missing values, which streamlined the analysis. However, the presence of outliers in several features required careful consideration during EDA. The correlation analysis revealed important relationships (e.g., alcohol positively correlated with quality) that informed our understanding of the problem.\n",
    "\n",
    "4. **Red vs White Wine Differences**: Red wine quality proved more predictable (best R² = 40.8%) than white wine (best R² = 37.8%). This suggests that the chemical composition of red wines may have more direct relationships with perceived quality, or that white wine quality involves factors not captured by the measured physicochemical properties.\n",
    "\n",
    "5. **Moderate Performance is Expected**: Our R² values (27-41%) align with published research showing that wine quality prediction has a natural ceiling around 40-55% due to the subjective nature of expert tasting. This taught us that \"good enough\" performance depends on the problem context and that perfect prediction isn't always achievable or necessary.\n",
    "\n",
    "### Challenges Faced\n",
    "\n",
    "1. **Overfitting Management**: Initially, Random Forest achieved training R² above 92% but poor test performance. We had to iteratively reduce model complexity (max_depth, min_samples_leaf) to find the right balance between learning capacity and generalization.\n",
    "\n",
    "2. **Hyperparameter Tuning**: Finding optimal hyperparameters for KNN (k values) and SVM (C, gamma).\n",
    "\n",
    "3. **Model Interpretability**: While we achieved good performance with SVM and Random Forest, these models are less interpretable than Linear Regression. Understanding which features drive predictions requires additional analysis (e.g., feature importance, sensitivity analysis).\n",
    "\n",
    "4. **Balancing Complexity and Performance**: There was a constant trade-off between model complexity and generalization. More complex models (SVM, Random Forest) performed better but required more tuning and were more prone to overfitting.\n",
    "\n",
    "### What Worked Well\n",
    "\n",
    "1. **Comprehensive EDA**: The thorough exploratory data analysis (missing values, distributions, outliers, correlations) provided valuable insights and helped us understand the data before modeling.\n",
    "\n",
    "2. **Separate Analysis for Wine Types**: Analyzing red and white wines separately was crucial, as they have different chemical profiles and quality determinants. This approach allowed us to optimize models for each wine type.\n",
    "\n",
    "3. **Consistent Evaluation Framework**: Using the same evaluation metrics (RMSE, R²) and train-test split methodology across all models enabled fair comparison and reliable performance assessment.\n",
    "\n",
    "4. **Pipeline Implementation**: Using scikit-learn Pipelines for KNN and SVM (with StandardScaler) ensured proper preprocessing and made the code more maintainable and reproducible.\n",
    "\n",
    "5. **Hyperparameter Tuning**: Systematic hyperparameter tuning (especially for KNN and SVM) significantly improved model performance and taught us the importance of proper model configuration.\n",
    "\n",
    "### Areas for Improvement\n",
    "\n",
    "1. **Feature Engineering**: We used all 11 features as-is without creating interaction terms or polynomial features. Exploring feature engineering (e.g., alcohol × acidity interactions) might have improved performance.\n",
    "\n",
    "2. **Cross-Validation**: We used a simple 70-30 train-test split. Implementing k-fold cross-validation would provide more robust performance estimates and better hyperparameter selection.\n",
    "\n",
    "3. **Feature Importance Analysis**: While we identified correlations, we didn't perform formal feature importance analysis (e.g., Random Forest feature importances, permutation importance) to understand which features most drive predictions.\n",
    "\n",
    "4. **Additional Models**: We could have explored other algorithms like Gradient Boosting (XGBoost, LightGBM) or Neural Networks, which might have achieved even better performance.\n",
    "\n",
    "5. **Error Analysis**: We didn't analyze prediction errors in detail (e.g., which quality scores are hardest to predict, systematic biases). This could provide insights for model improvement.\n",
    "\n",
    "6. **Ensemble Methods**: Combining multiple models (e.g., averaging SVM and Random Forest predictions) might have improved performance beyond individual models.\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "The models we developed, while not perfect, have practical value:\n",
    "\n",
    "- **Production Optimization**: Understanding which chemical properties correlate with quality (e.g., alcohol content, sulphates) can guide production decisions and process improvements.\n",
    "\n",
    "- **Decision Support**: The models can serve as decision support tools for oenologists, providing objective predictions that complement subjective expert evaluations.\n",
    "\n",
    "- **Research Foundation**: The moderate R² values (27-41%) confirm that expert wine tasting involves factors beyond chemical composition alone, suggesting opportunities for future research incorporating additional features (e.g., grape variety, region, vintage, production methods).\n",
    "\n",
    "### Overall Conclusions\n",
    "\n",
    "This project successfully demonstrated that machine learning can predict wine quality from physicochemical properties with meaningful accuracy. While the moderate R² values reflect the inherent challenge of predicting subjective expert ratings, the models provide valuable insights and practical utility.\n",
    "\n",
    "The finding that different models excel for different wine types (SVM for red, Random Forest for white) highlights that there's no \"one-size-fits-all\" solution in machine learning. Context matters, and the best approach depends on the specific characteristics of the data and problem domain.\n",
    "\n",
    "**Final Recommendation**: For production deployment, we recommend using SVM for red wine quality prediction and Random Forest for white wine, as these models achieved the best performance for their respective wine types. However, the choice between models should also consider computational resources, interpretability requirements, and the specific use case (e.g., real-time prediction vs. batch processing).\n",
    "\n",
    "This project provided valuable hands-on experience with the complete data science pipeline, from data exploration through model deployment considerations, and demonstrated both the potential and limitations of machine learning for predicting subjective quality assessments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
